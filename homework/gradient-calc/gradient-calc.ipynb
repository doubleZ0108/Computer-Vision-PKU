{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算机视觉第四次作业 - 矩阵导数问题\n",
    "\n",
    "- 学号：2101212846\n",
    "- 姓名：张喆\n",
    "- 指导老师：张健"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 问题描述\n",
    "\n",
    "目标函数：$f = ||max(XW, 0)-Y||^2_F$\n",
    "\n",
    "手动写出以下表达式，并用PyTorch进行验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 问题求解\n",
    "\n",
    "对于本问题，首先不考虑`max()`函数，将原始目标函数进行简化，并令$Z = XW - Y$\n",
    "\n",
    "则原式F范数的平方问题化简为$f = tr(Z^TZ)$\n",
    "\n",
    "\n",
    "\n",
    "### 2.1 $\\frac{\\partial f}{\\partial Y}$\n",
    "\n",
    "由导数的链式法则，$\\frac{\\partial f}{\\partial Y} = \\frac{\\partial f}{\\partial Z}\\frac{\\partial Z}{\\partial Y}$\n",
    "\n",
    "- $\\frac{\\partial f}{\\partial Z}$根据公式$\\frac{\\partial tr(AXBX^T)}{\\partial X} = AXB+A^TXB^T$，可化简为$\\frac{\\partial Z^T Z}{\\partial Z} = \\frac{\\partial Z Z^T}{\\partial Z} = EZE+E^TZE^T = 2Z$\n",
    "- $\\frac{\\partial Z}{\\partial Y} = -1$\n",
    "\n",
    "综上$\\frac{\\partial f}{\\partial Y} = \\frac{\\partial f}{\\partial Z}\\frac{\\partial Z}{\\partial Y} = -2Z = 2(Y-XW)$\n",
    "\n",
    "\n",
    "\n",
    "### 2.2 $\\frac{\\partial f}{\\partial X}$\n",
    "\n",
    "由导数的链式法则，$\\frac{\\partial f}{\\partial X} = \\frac{\\partial f}{\\partial Z}\\frac{\\partial Z}{\\partial X}$\n",
    "\n",
    "- $\\frac{\\partial f}{\\partial Z}$在上已经计算\n",
    "- $\\frac{\\partial Z}{\\partial X}$根据公式$\\frac{\\partial tr(AB)}{\\partial A} = B^T$，可化简为$\\frac{\\partial (XW-Y)}{\\partial X} = \\frac{\\partial XW}{\\partial X} - \\frac{\\partial Y}{\\partial X} = W^T$\n",
    "\n",
    "综上，$\\frac{\\partial f}{\\partial X} = \\frac{\\partial f}{\\partial Z}\\frac{\\partial Z}{\\partial X} = 2ZW^T$\n",
    "\n",
    "\n",
    "\n",
    "### 2.3 $\\frac{\\partial f}{\\partial W}$\n",
    "\n",
    "同理，$\\frac{\\partial f}{\\partial W} = 2X^TZ$\n",
    "\n",
    "\n",
    "\n",
    "### 2.4 考虑max函数\n",
    "\n",
    "由于max函数的存在，还需要计算其对各元素的偏导\n",
    "\n",
    "记函数$\\sigma$表达式如下\n",
    "$$\n",
    "\\sigma_{i j} = \\begin{cases}1, & (X W)_{i j}>0 \\\\ 0, & \\text { otherwise }\\end{cases}\n",
    "$$\n",
    "还需要将之前的计算公式进行修正, $\\frac{\\partial f}{\\partial X} = 2(Z \\odot \\sigma)W^T$, $\\frac{\\partial f}{\\partial W} = 2X^T(Z \\odot \\sigma)$，其中$\\odot$代表对位相乘\n",
    "\n",
    "综上\n",
    "\n",
    "- $\\frac{\\partial f}{\\partial Y} = -2Z = 2(Y-XW)$\n",
    "- $\\frac{\\partial f}{\\partial X} = 2(Z \\odot \\sigma)W^T$\n",
    "- $\\frac{\\partial f}{\\partial W} = 2X^T(Z \\odot \\sigma)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 PyTorch验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f99c3df1910>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([[-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "        [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "        [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "        [ 0.1198,  1.2377,  1.1168, -0.2473],\n",
      "        [-1.3527, -1.6959,  0.5667,  0.7935],\n",
      "        [ 0.5988, -1.5551, -0.3414,  1.8530],\n",
      "        [-0.2159, -0.7425,  0.5627,  0.2596],\n",
      "        [-0.1740, -0.6787,  0.9383,  0.4889],\n",
      "        [ 1.2032,  0.0845, -1.2001, -0.0048],\n",
      "        [-0.5181, -0.3067, -1.5810,  1.7066]], requires_grad=True)\n",
      "W:  tensor([[ 0.2055, -0.4503, -0.5731, -0.5554],\n",
      "        [ 0.5943,  1.5419,  0.5073, -0.5910],\n",
      "        [-1.3253,  0.1886, -0.0691, -0.4949],\n",
      "        [-1.4959, -0.1938,  0.4455,  1.3253]], requires_grad=True)\n",
      "y:  tensor([[ 1.5091,  2.0820,  1.7067,  2.3804],\n",
      "        [-1.1256, -0.3170, -1.0925, -0.0852],\n",
      "        [ 0.3276, -0.7607, -1.5991,  0.0185],\n",
      "        [-0.7504,  0.1854,  0.6211,  0.6382],\n",
      "        [-0.0033, -0.5344,  1.1687,  0.3945],\n",
      "        [ 1.9415,  0.7915, -0.0203, -0.4372],\n",
      "        [-0.2188, -2.4351, -0.0729, -0.0340],\n",
      "        [ 0.9625,  0.3492, -0.9215, -0.0562],\n",
      "        [-0.6227, -0.4637,  1.9218, -0.4025],\n",
      "        [ 0.1239,  1.1648,  0.9234,  1.3873]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 4, requires_grad=True)\n",
    "W = torch.randn(4, 4, requires_grad=True)\n",
    "y = torch.randn(10, 4, requires_grad=True)\n",
    "\n",
    "print(\"x: \", x)\n",
    "print(\"W: \", W)\n",
    "print(\"y: \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(99.9048, grad_fn=<TraceBackward>)\n"
     ]
    }
   ],
   "source": [
    "q = x.mm(W)\n",
    "p = torch.max(q, torch.zeros_like(q)) - y\n",
    "f = torch.trace(p.t().mm(p))\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(99.9048, grad_fn=<TraceBackward>)\n"
     ]
    }
   ],
   "source": [
    "q = x.mm(W)\n",
    "f = torch.trace((torch.max(x.mm(W), torch.zeros_like(q)) - y).t().mm(torch.max(x.mm(W), torch.zeros_like(q)) - y))\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W grad:  tensor([[ 18.2980,   2.7573,   2.3914,  -0.1974],\n",
      "        [ 11.0817,   6.6428,   2.5163, -20.3225],\n",
      "        [ -8.6662,   3.4506,  -1.8979,  -3.3608],\n",
      "        [-21.1681,  -6.6739,  -1.0693,  27.0278]])\n",
      "x grad:  tensor([[  1.1002,   0.0860,   5.3377,   0.2788],\n",
      "        [  0.9583,  10.4633, -13.5234, -16.3639],\n",
      "        [ -0.8712,  -0.9272,  -0.7764,   2.0790],\n",
      "        [ -1.4504,   5.6914,   0.7613,  -0.9693],\n",
      "        [ -1.2892,  -3.4714,  -1.9788,   4.8091],\n",
      "        [ -4.0523,  -4.3127,  -3.6114,   9.6703],\n",
      "        [ -0.7312,  -0.7782,  -0.6516,   1.7449],\n",
      "        [ -0.8191,  -0.8718,  -0.7300,   1.9547],\n",
      "        [  1.0350,   2.9930,  -6.6743,  -7.5333],\n",
      "        [ -2.4616,  -2.4243,  -2.1164,   5.7128]])\n",
      "y grad:  tensor([[ 2.8885e+00,  4.1639e+00,  3.4134e+00,  3.0501e+00],\n",
      "        [-1.0589e+01, -2.7045e+00, -2.1849e+00, -1.7039e-01],\n",
      "        [ 6.5523e-01, -1.5214e+00, -3.1982e+00, -1.5687e+00],\n",
      "        [-1.5009e+00, -3.8551e+00,  4.9843e-01,  1.2764e+00],\n",
      "        [-6.6077e-03, -1.0689e+00,  1.8791e+00, -4.2604e+00],\n",
      "        [ 3.8829e+00,  1.5830e+00, -4.0504e-02, -7.2968e+00],\n",
      "        [-4.3767e-01, -4.8701e+00, -1.4583e-01, -1.3166e+00],\n",
      "        [ 1.9250e+00,  6.9834e-01, -1.8429e+00, -1.4750e+00],\n",
      "        [-5.0359e+00, -9.2744e-01,  3.8436e+00, -8.0509e-01],\n",
      "        [ 2.4780e-01,  2.3296e+00, -1.7491e-01, -4.2519e+00]])\n"
     ]
    }
   ],
   "source": [
    "f.backward()\n",
    "\n",
    "print(\"W grad: \", W.grad)\n",
    "print(\"x grad: \", x.grad)\n",
    "print(\"y grad: \", y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "af_ay:  tensor([[ 2.8885e+00,  4.1639e+00,  3.4134e+00,  3.0501e+00],\n",
      "        [-1.0589e+01, -2.7045e+00, -2.1849e+00, -1.7039e-01],\n",
      "        [ 6.5523e-01, -1.5214e+00, -3.1982e+00, -1.5687e+00],\n",
      "        [-1.5009e+00, -3.8551e+00,  4.9843e-01,  1.2764e+00],\n",
      "        [-6.6077e-03, -1.0689e+00,  1.8791e+00, -4.2604e+00],\n",
      "        [ 3.8829e+00,  1.5830e+00, -4.0504e-02, -7.2968e+00],\n",
      "        [-4.3767e-01, -4.8701e+00, -1.4583e-01, -1.3166e+00],\n",
      "        [ 1.9250e+00,  6.9834e-01, -1.8429e+00, -1.4750e+00],\n",
      "        [-5.0359e+00, -9.2744e-01,  3.8436e+00, -8.0509e-01],\n",
      "        [ 2.4780e-01,  2.3296e+00, -1.7491e-01, -4.2519e+00]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "q = x.mm(W)\n",
    "p = torch.max(q, torch.zeros_like(q))\n",
    "af_ay = 2 * (y - p)\n",
    "print(\"af_ay: \", af_ay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06488088 -1.2330197  -0.11542916  0.8553368 ]\n",
      " [ 4.168717    1.0352616  -1.0558246  -3.527183  ]\n",
      " [-1.609377   -2.086857   -0.71251845  0.8028413 ]\n",
      " [-0.34998763  2.1129332   0.3719238  -1.6784847 ]\n",
      " [-3.2239537  -2.052856    0.22914815  2.5247262 ]\n",
      " [-3.1206777  -3.0910888  -0.2830189   3.2112324 ]\n",
      " [-1.6198487  -0.99197924 -0.17621547  0.6243247 ]\n",
      " [-2.413957   -0.8860966  -0.09166898  0.6812901 ]\n",
      " [ 1.8952693  -0.6368627  -0.5658878  -0.13054621]\n",
      " [-0.74642    -0.8685286   1.0108292   3.5132349 ]]\n",
      "tensor([[1., 0., 0., 1.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "sigma = torch.mm(x, W).detach().numpy()\n",
    "print(sigma)\n",
    "sigma[sigma > 0] = 1\n",
    "sigma[sigma < 0] = 0\n",
    "sigma = torch.from_numpy(sigma)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "af_ax:  tensor([[  1.1002,   0.0860,   5.3377,   0.2788],\n",
      "        [  0.9583,  10.4633, -13.5234, -16.3639],\n",
      "        [ -0.8712,  -0.9272,  -0.7764,   2.0790],\n",
      "        [ -1.4504,   5.6914,   0.7613,  -0.9693],\n",
      "        [ -1.2892,  -3.4714,  -1.9788,   4.8091],\n",
      "        [ -4.0523,  -4.3127,  -3.6114,   9.6703],\n",
      "        [ -0.7312,  -0.7782,  -0.6516,   1.7449],\n",
      "        [ -0.8191,  -0.8718,  -0.7300,   1.9547],\n",
      "        [  1.0350,   2.9930,  -6.6743,  -7.5333],\n",
      "        [ -2.4616,  -2.4243,  -2.1164,   5.7128]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = torch.mm(x, W) - y\n",
    "af_ax = 2 * torch.mm(z * sigma, W.t())\n",
    "print(\"af_ax: \", af_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "af_aW:  tensor([[ 18.2980,   2.7573,   2.3914,  -0.1974],\n",
      "        [ 11.0817,   6.6428,   2.5163, -20.3225],\n",
      "        [ -8.6662,   3.4506,  -1.8979,  -3.3608],\n",
      "        [-21.1681,  -6.6739,  -1.0693,  27.0278]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "af_aW = 2 * torch.mm(x.t(), z * sigma)\n",
    "print(\"af_aW: \", af_aW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad == af_ax ?  True\n",
      "W.grad == af_aW ?  True\n",
      "y.grad == af_ay ?  True\n"
     ]
    }
   ],
   "source": [
    "print(\"x.grad == af_ax ? \", torch.equal(x.grad, af_ax))\n",
    "print(\"W.grad == af_aW ? \", torch.equal(W.grad, af_aW))\n",
    "print(\"y.grad == af_ay ? \", torch.equal(y.grad, af_ay))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eaec372a0783a1fe676e24615e6d5d9daeb747ab1ec5a93128d336745d088419"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('cv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
